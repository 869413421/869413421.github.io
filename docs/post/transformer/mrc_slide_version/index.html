<!DOCTYPE html>






































<html
  class="not-ready text-sm lg:text-base"
  style="--bg: #fff"
  lang="en-zh"
>
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1, shrink-to-fit=no"
  />

  
  <title>Transformer 学习之路 - 基于滑动窗口策略的机器阅读理解任务实现 - 清水泥沙</title>

  
  <meta name="theme-color" />
  
  <meta name="description" content="Transformer 学习之路 - 基于滑动窗口策略的机器阅读理解任务实现 在自然语言处理（NLP）领域，机器阅读理解（Machine Reading Comprehension, MRC）是一个重要的任务，其目标是通过理解给定的上下文文本，回答用户提出的问题。本文将深入探讨如何利用 Transformer 模型，并结合滑动窗口策略来实现这一任务。
1. 背景与问题 机器阅读理解任务的核心挑战在于如何有效地处理长文本。传统的 Transformer 模型由于输入长度的限制，往往无法直接处理过长的上下文文本。为了解决这一问题，滑动窗口策略应运而生。通过将长文本分割成多个片段，并逐步滑动窗口进行处理，模型能够在不损失信息的情况下处理长文本。
2. 滑动窗口策略的实现 滑动窗口策略的核心思想是将长文本分割成多个重叠的片段，每个片段都包含一部分上下文信息。这样，模型可以在每个片段上独立地进行处理，最终将所有片段的结果进行整合。
2.1 数据预处理 首先，我们需要对数据进行预处理。以下代码展示了如何加载数据集，并使用滑动窗口策略对数据进行编码：
from datasets import load_dataset from transformers import AutoTokenizer # 加载数据集 datasets = load_dataset(&#34;cmrc2018&#34;, cache_dir=&#34;data&#34;) # 加载预训练的 tokenizer tokenizer = AutoTokenizer.from_pretrained(&#34;hfl/chinese-macbert-base&#34;) # 对数据进行编码，使用滑动窗口策略 tokenized_examples = tokenizer( text=sample_dataset[&#34;context&#34;], text_pair=sample_dataset[&#34;question&#34;], return_offsets_mapping=True, max_length=384, return_overflowing_tokens=True, # 设置滑动窗口策略 stride=128, # 覆盖策略，每次移动128个字符 truncation_strategy=&#34;only_second&#34;, ) 2.2 滑动窗口的处理 在处理滑动窗口时，我们需要确保每个片段都能够正确地定位答案的位置。以下代码展示了如何在滑动窗口的每个片段中定位答案的起始和结束位置：
for idx, _ in enumerate(sample_mapping): answer = sample_dataset[&#34;answers&#34;][sample_mapping[idx]] start_char = answer[&#34;answer_start&#34;][0] end_char = start_char &#43; len(answer[&#34;text&#34;][0]) # 定位答案在token中的起始位置和结束位置 context_start = tokenized_examples." />
  <meta
    name="author"
    content=""
  />
  

  
  
  
  
  
  
  <link rel="preload stylesheet" as="style" href="https://869413421.github.io/main.min.css" />

  

  
     
  <link rel="preload" as="image" href="https://869413421.github.io/theme.png" />

  
  
  
  <link rel="preload" as="image" href="https://www.gravatar.com/avatar/6fd8df4abe41f17fd8e2dd7d97b5cc8c?s=160&amp;d=identicon" />
  
  

  
  <link rel="preload" as="image" href="https://869413421.github.io/github.svg" />
  
  <link rel="preload" as="image" href="https://869413421.github.io/rss.svg" />
  

  
  <link rel="icon" href="https://869413421.github.io/favicon.ico" />
  <link rel="apple-touch-icon" href="https://869413421.github.io/apple-touch-icon.png" />

  
  <meta name="generator" content="Hugo 0.110.0">

  
  

  
  
  
  
  
  
  
  
  
  <meta property="og:title" content="Transformer 学习之路 - 基于滑动窗口策略的机器阅读理解任务实现" />
<meta property="og:description" content="深入解析基于滑动窗口策略的机器阅读理解任务，结合代码示例讲解 Transformer 技术在实际应用中的实现。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://869413421.github.io/post/transformer/mrc_slide_version/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2024-04-19T17:35:18+08:00" />
<meta property="article:modified_time" content="2024-04-19T17:35:18+08:00" />

  
  <meta itemprop="name" content="Transformer 学习之路 - 基于滑动窗口策略的机器阅读理解任务实现">
<meta itemprop="description" content="深入解析基于滑动窗口策略的机器阅读理解任务，结合代码示例讲解 Transformer 技术在实际应用中的实现。"><meta itemprop="datePublished" content="2024-04-19T17:35:18+08:00" />
<meta itemprop="dateModified" content="2024-04-19T17:35:18+08:00" />
<meta itemprop="wordCount" content="371">
<meta itemprop="keywords" content="" />
  
  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Transformer 学习之路 - 基于滑动窗口策略的机器阅读理解任务实现"/>
<meta name="twitter:description" content="深入解析基于滑动窗口策略的机器阅读理解任务，结合代码示例讲解 Transformer 技术在实际应用中的实现。"/>

  
  
</head>

  <body class="text-black duration-200 ease-out dark:text-white">
    <header class="mx-auto flex h-[5rem] max-w-3xl px-8 lg:justify-center">
  <div class="relative z-50 mr-auto flex items-center">
    <a
      class="-translate-x-[1px] -translate-y-0.5 text-3xl font-bold"
      href="https://869413421.github.io/"
      >清水泥沙</a
    >
    <a
      class="btn-dark ml-6 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.svg)_left_center/cover_no-repeat] dark:invert dark:[background-position:right]"
    ></a>
  </div>

  <a
    class="btn-menu relative z-50 -mr-8 flex h-[5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden"
  ></a>

  
  <script>
    
    const htmlClass = document.documentElement.classList;
    setTimeout(() => {
      htmlClass.remove('not-ready');
    }, 10);

    
    const btnMenu = document.querySelector('.btn-menu');
    btnMenu.addEventListener('click', () => {
      htmlClass.toggle('open');
    });

    
    const metaTheme = document.querySelector('meta[name="theme-color"]');
    const lightBg = `"#fff"`.replace(/"/g, '');
    const setDark = (isDark) => {
      metaTheme.setAttribute('content', isDark ? '#000' : lightBg);
      htmlClass[isDark ? 'add' : 'remove']('dark');
      localStorage.setItem('dark', isDark);
    };

    
    const darkScheme = window.matchMedia('(prefers-color-scheme: dark)');
    if (htmlClass.contains('dark')) {
      setDark(true);
    } else {
      const darkVal = localStorage.getItem('dark');
      setDark(darkVal ? darkVal === 'true' : darkScheme.matches);
    }

    
    darkScheme.addEventListener('change', (event) => {
      setDark(event.matches);
    });

    
    const btnDark = document.querySelector('.btn-dark');
    btnDark.addEventListener('click', () => {
      setDark(localStorage.getItem('dark') !== 'true');
    });
  </script>

  <div
    class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"
  >
    
    
    <nav class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-6">
      
      <a
        class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal"
        href="/tags"
        >标签</a
      >
      
      <a
        class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal"
        href="/categories"
        >分类</a
      >
      
      <a
        class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal"
        href="/about/"
        >个人简历</a
      >
      
    </nav>
    

    
    <nav
      class="mt-12 flex justify-center space-x-10 dark:invert lg:mt-0 lg:ml-12 lg:items-center lg:space-x-6"
    >
      
      <a
        class="h-8 w-8 [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./github.svg)"
        href=" https://github.com/869413421 "
        target="_blank"
      ></a>
      
      <a
        class="h-8 w-8 [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./rss.svg)"
        href=" https://869413421.github.io/index.xml "
        target="_blank"
      ></a>
      
    </nav>
    
  </div>
</header>


    <main
      class="prose prose-neutral relative mx-auto min-h-[calc(100%-10rem)] max-w-3xl px-8 pt-20 pb-32 dark:prose-invert"
    >
      

<article>
  <header class="mb-20">
    <h1 class="!my-0 pb-2.5">Transformer 学习之路 - 基于滑动窗口策略的机器阅读理解任务实现</h1>

    
    <div class="text-sm opacity-60">
      
      <time>Apr 19, 2024</time>
      
      
    </div>
    
  </header>

  <section><h1 id="transformer-学习之路---基于滑动窗口策略的机器阅读理解任务实现">Transformer 学习之路 - 基于滑动窗口策略的机器阅读理解任务实现</h1>
<p>在自然语言处理（NLP）领域，机器阅读理解（Machine Reading Comprehension, MRC）是一个重要的任务，其目标是通过理解给定的上下文文本，回答用户提出的问题。本文将深入探讨如何利用 Transformer 模型，并结合滑动窗口策略来实现这一任务。</p>
<h2 id="1-背景与问题">1. 背景与问题</h2>
<p>机器阅读理解任务的核心挑战在于如何有效地处理长文本。传统的 Transformer 模型由于输入长度的限制，往往无法直接处理过长的上下文文本。为了解决这一问题，滑动窗口策略应运而生。通过将长文本分割成多个片段，并逐步滑动窗口进行处理，模型能够在不损失信息的情况下处理长文本。</p>
<h2 id="2-滑动窗口策略的实现">2. 滑动窗口策略的实现</h2>
<p>滑动窗口策略的核心思想是将长文本分割成多个重叠的片段，每个片段都包含一部分上下文信息。这样，模型可以在每个片段上独立地进行处理，最终将所有片段的结果进行整合。</p>
<h3 id="21-数据预处理">2.1 数据预处理</h3>
<p>首先，我们需要对数据进行预处理。以下代码展示了如何加载数据集，并使用滑动窗口策略对数据进行编码：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> datasets <span style="color:#f92672">import</span> load_dataset
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> AutoTokenizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 加载数据集</span>
</span></span><span style="display:flex;"><span>datasets <span style="color:#f92672">=</span> load_dataset(<span style="color:#e6db74">&#34;cmrc2018&#34;</span>, cache_dir<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;data&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 加载预训练的 tokenizer</span>
</span></span><span style="display:flex;"><span>tokenizer <span style="color:#f92672">=</span> AutoTokenizer<span style="color:#f92672">.</span>from_pretrained(<span style="color:#e6db74">&#34;hfl/chinese-macbert-base&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 对数据进行编码，使用滑动窗口策略</span>
</span></span><span style="display:flex;"><span>tokenized_examples <span style="color:#f92672">=</span> tokenizer(
</span></span><span style="display:flex;"><span>    text<span style="color:#f92672">=</span>sample_dataset[<span style="color:#e6db74">&#34;context&#34;</span>],
</span></span><span style="display:flex;"><span>    text_pair<span style="color:#f92672">=</span>sample_dataset[<span style="color:#e6db74">&#34;question&#34;</span>],
</span></span><span style="display:flex;"><span>    return_offsets_mapping<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>    max_length<span style="color:#f92672">=</span><span style="color:#ae81ff">384</span>,
</span></span><span style="display:flex;"><span>    return_overflowing_tokens<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,  <span style="color:#75715e"># 设置滑动窗口策略</span>
</span></span><span style="display:flex;"><span>    stride<span style="color:#f92672">=</span><span style="color:#ae81ff">128</span>,  <span style="color:#75715e"># 覆盖策略，每次移动128个字符</span>
</span></span><span style="display:flex;"><span>    truncation_strategy<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;only_second&#34;</span>,
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><h3 id="22-滑动窗口的处理">2.2 滑动窗口的处理</h3>
<p>在处理滑动窗口时，我们需要确保每个片段都能够正确地定位答案的位置。以下代码展示了如何在滑动窗口的每个片段中定位答案的起始和结束位置：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> idx, _ <span style="color:#f92672">in</span> enumerate(sample_mapping):
</span></span><span style="display:flex;"><span>    answer <span style="color:#f92672">=</span> sample_dataset[<span style="color:#e6db74">&#34;answers&#34;</span>][sample_mapping[idx]]
</span></span><span style="display:flex;"><span>    start_char <span style="color:#f92672">=</span> answer[<span style="color:#e6db74">&#34;answer_start&#34;</span>][<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>    end_char <span style="color:#f92672">=</span> start_char <span style="color:#f92672">+</span> len(answer[<span style="color:#e6db74">&#34;text&#34;</span>][<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 定位答案在token中的起始位置和结束位置</span>
</span></span><span style="display:flex;"><span>    context_start <span style="color:#f92672">=</span> tokenized_examples<span style="color:#f92672">.</span>sequence_ids(idx)<span style="color:#f92672">.</span>index(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    context_end <span style="color:#f92672">=</span> tokenized_examples<span style="color:#f92672">.</span>sequence_ids(idx)<span style="color:#f92672">.</span>index(<span style="color:#66d9ef">None</span>, context_start) <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    offset <span style="color:#f92672">=</span> tokenized_examples<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;offset_mapping&#34;</span>)[idx]
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 判断答案是否在context中</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> offset[context_end][<span style="color:#ae81ff">1</span>] <span style="color:#f92672">&lt;</span> start_char <span style="color:#f92672">or</span> offset[context_start][<span style="color:#ae81ff">0</span>] <span style="color:#f92672">&gt;</span> end_char:
</span></span><span style="display:flex;"><span>        start_token_pos <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        end_token_pos <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        token_id <span style="color:#f92672">=</span> context_start
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">while</span> token_id <span style="color:#f92672">&lt;=</span> context_end <span style="color:#f92672">and</span> offset[token_id][<span style="color:#ae81ff">0</span>] <span style="color:#f92672">&lt;</span> start_char:
</span></span><span style="display:flex;"><span>            token_id <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        start_token_pos <span style="color:#f92672">=</span> token_id
</span></span><span style="display:flex;"><span>        token_id <span style="color:#f92672">=</span> context_end
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">while</span> token_id <span style="color:#f92672">&gt;=</span> context_start <span style="color:#f92672">and</span> offset[token_id][<span style="color:#ae81ff">1</span>] <span style="color:#f92672">&gt;</span> end_char:
</span></span><span style="display:flex;"><span>            token_id <span style="color:#f92672">-=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        end_token_pos <span style="color:#f92672">=</span> token_id
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    print(answer, start_char, end_char, context_start, context_end, start_token_pos, end_token_pos)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;token answer decode:&#34;</span>, tokenizer<span style="color:#f92672">.</span>decode(tokenized_examples[<span style="color:#e6db74">&#34;input_ids&#34;</span>][idx][start_token_pos: end_token_pos <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>]))
</span></span></code></pre></div><h2 id="3-模型训练与评估">3. 模型训练与评估</h2>
<p>在完成数据预处理后，我们可以开始训练模型。以下代码展示了如何加载模型、配置训练参数，并进行训练：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> AutoModelForQuestionAnswering, Trainer, TrainingArguments
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 加载预训练模型</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> AutoModelForQuestionAnswering<span style="color:#f92672">.</span>from_pretrained(<span style="color:#e6db74">&#34;hfl/chinese-macbert-base&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 配置训练参数</span>
</span></span><span style="display:flex;"><span>args <span style="color:#f92672">=</span> TrainingArguments(
</span></span><span style="display:flex;"><span>    output_dir<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;models_for_qa&#34;</span>,
</span></span><span style="display:flex;"><span>    per_device_train_batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>,
</span></span><span style="display:flex;"><span>    per_device_eval_batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>,
</span></span><span style="display:flex;"><span>    eval_strategy<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;steps&#34;</span>,
</span></span><span style="display:flex;"><span>    eval_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">200</span>,
</span></span><span style="display:flex;"><span>    save_strategy<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;epoch&#34;</span>,
</span></span><span style="display:flex;"><span>    logging_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>,
</span></span><span style="display:flex;"><span>    num_train_epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 创建 Trainer</span>
</span></span><span style="display:flex;"><span>trainer <span style="color:#f92672">=</span> Trainer(
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">=</span>model,
</span></span><span style="display:flex;"><span>    args<span style="color:#f92672">=</span>args,
</span></span><span style="display:flex;"><span>    train_dataset<span style="color:#f92672">=</span>tokenized_datasets[<span style="color:#e6db74">&#34;train&#34;</span>],
</span></span><span style="display:flex;"><span>    eval_dataset<span style="color:#f92672">=</span>tokenized_datasets[<span style="color:#e6db74">&#34;validation&#34;</span>],
</span></span><span style="display:flex;"><span>    data_collator<span style="color:#f92672">=</span>DefaultDataCollator(),
</span></span><span style="display:flex;"><span>    tokenizer<span style="color:#f92672">=</span>tokenizer,
</span></span><span style="display:flex;"><span>    compute_metrics<span style="color:#f92672">=</span>metirc
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 训练模型</span>
</span></span><span style="display:flex;"><span>trainer<span style="color:#f92672">.</span>train()
</span></span></code></pre></div><h3 id="31-模型评估">3.1 模型评估</h3>
<p>在训练完成后，我们需要对模型进行评估。以下代码展示了如何获取模型的输出，并进行评估：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> collections
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_result</span>(start_logits, end_logits, examples, features):
</span></span><span style="display:flex;"><span>    predictions <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span>    references <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># example 和 feature的映射</span>
</span></span><span style="display:flex;"><span>    example_to_feature <span style="color:#f92672">=</span> collections<span style="color:#f92672">.</span>defaultdict(list)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> idx, example_id <span style="color:#f92672">in</span> enumerate(features[<span style="color:#e6db74">&#34;example_ids&#34;</span>]):
</span></span><span style="display:flex;"><span>        example_to_feature[example_id]<span style="color:#f92672">.</span>append(idx)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 最优答案候选</span>
</span></span><span style="display:flex;"><span>    n_best <span style="color:#f92672">=</span> <span style="color:#ae81ff">20</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 最大答案长度</span>
</span></span><span style="display:flex;"><span>    max_answer_length <span style="color:#f92672">=</span> <span style="color:#ae81ff">30</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> example <span style="color:#f92672">in</span> examples:
</span></span><span style="display:flex;"><span>        example_id <span style="color:#f92672">=</span> example[<span style="color:#e6db74">&#34;id&#34;</span>]
</span></span><span style="display:flex;"><span>        context <span style="color:#f92672">=</span> example[<span style="color:#e6db74">&#34;context&#34;</span>]
</span></span><span style="display:flex;"><span>        answers <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> feature_idx <span style="color:#f92672">in</span> example_to_feature[example_id]:
</span></span><span style="display:flex;"><span>            start_logit <span style="color:#f92672">=</span> start_logits[feature_idx]
</span></span><span style="display:flex;"><span>            end_logit <span style="color:#f92672">=</span> end_logits[feature_idx]
</span></span><span style="display:flex;"><span>            offset <span style="color:#f92672">=</span> features[feature_idx][<span style="color:#e6db74">&#34;offset_mapping&#34;</span>]
</span></span><span style="display:flex;"><span>            start_indexes <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argsort(start_logit)[::<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>][:n_best]<span style="color:#f92672">.</span>tolist()
</span></span><span style="display:flex;"><span>            end_indexes <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argsort(end_logit)[::<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>][:n_best]<span style="color:#f92672">.</span>tolist()
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> start_index <span style="color:#f92672">in</span> start_indexes:
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">for</span> end_index <span style="color:#f92672">in</span> end_indexes:
</span></span><span style="display:flex;"><span>                    <span style="color:#66d9ef">if</span> offset[start_index] <span style="color:#f92672">is</span> <span style="color:#66d9ef">None</span> <span style="color:#f92672">or</span> offset[end_index] <span style="color:#f92672">is</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>                        <span style="color:#66d9ef">continue</span>
</span></span><span style="display:flex;"><span>                    <span style="color:#66d9ef">if</span> end_index <span style="color:#f92672">&lt;</span> start_index <span style="color:#f92672">or</span> end_index <span style="color:#f92672">-</span> start_index <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">&gt;</span> max_answer_length:
</span></span><span style="display:flex;"><span>                        <span style="color:#66d9ef">continue</span>
</span></span><span style="display:flex;"><span>                    answers<span style="color:#f92672">.</span>append({
</span></span><span style="display:flex;"><span>                        <span style="color:#e6db74">&#34;text&#34;</span>: context[offset[start_index][<span style="color:#ae81ff">0</span>]: offset[end_index][<span style="color:#ae81ff">1</span>]],
</span></span><span style="display:flex;"><span>                        <span style="color:#e6db74">&#34;score&#34;</span>: start_logit[start_index] <span style="color:#f92672">+</span> end_logit[end_index]
</span></span><span style="display:flex;"><span>                    })
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> len(answers) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>            best_answer <span style="color:#f92672">=</span> max(answers, key<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> x: x[<span style="color:#e6db74">&#34;score&#34;</span>])
</span></span><span style="display:flex;"><span>            predictions[example_id] <span style="color:#f92672">=</span> best_answer[<span style="color:#e6db74">&#34;text&#34;</span>]
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            predictions[example_id] <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        references[example_id] <span style="color:#f92672">=</span> example[<span style="color:#e6db74">&#34;answers&#34;</span>][<span style="color:#e6db74">&#34;text&#34;</span>]
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> predictions, references
</span></span></code></pre></div><h2 id="4-模型预测与保存">4. 模型预测与保存</h2>
<p>在模型训练和评估完成后，我们可以使用模型进行预测，并将模型保存以备后续使用：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> pipeline
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 使用模型进行预测</span>
</span></span><span style="display:flex;"><span>qa <span style="color:#f92672">=</span> pipeline(<span style="color:#e6db74">&#34;question-answering&#34;</span>, model<span style="color:#f92672">=</span>model, tokenizer<span style="color:#f92672">=</span>tokenizer)
</span></span><span style="display:flex;"><span>result <span style="color:#f92672">=</span> qa(question<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;信宜在哪里&#34;</span>, context<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;广东茂名信宜的特色是三华李炒猪大肠。&#34;</span>)
</span></span><span style="display:flex;"><span>print(result)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 保存模型</span>
</span></span><span style="display:flex;"><span>model_save_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/content/drive/MyDrive/ai-learning/2.NLP Task/03-question_answering/mrc2&#34;</span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>save_pretrained(model_save_path)
</span></span></code></pre></div><h2 id="5-总结">5. 总结</h2>
<p>通过本文的讲解，我们深入探讨了如何利用 Transformer 模型和滑动窗口策略来实现机器阅读理解任务。滑动窗口策略有效地解决了长文本处理的问题，使得模型能够在有限的输入长度内处理更长的上下文。结合代码示例，我们展示了从数据预处理、模型训练到模型预测的完整流程，希望能够帮助读者更好地理解和应用 Transformer 技术。</p>
</section>

  
  

  
  
  
  <nav class="mt-24 flex rounded-lg bg-black/[3%] text-lg dark:bg-white/[8%]">
    
    <a
      class="flex w-1/2 items-center rounded-l-md p-6 pr-3 no-underline hover:bg-black/[2%]"
      href="https://869413421.github.io/post/transformer/summarizatioin/"
      ><span class="mr-1.5">←</span><span>Transformer 学习之路 - 基于 T5 的文本摘要</span></a
    >
    
    
    <a
      class="ml-auto flex w-1/2 items-center justify-end rounded-r-md p-6 pl-3 no-underline hover:bg-black/[2%]"
      href="https://869413421.github.io/post/transformer/masked_lm/"
      ><span>Transformer 学习之路 - 掩码语言模型训练与实战</span><span class="ml-1.5">→</span></a
    >
    
  </nav>
  

  
  

  
  
</article>


    </main>

    <footer
  class="opaco mx-auto flex h-[5rem] max-w-3xl items-center px-8 text-[0.9em] opacity-60"
>
  <div class="mr-auto">
    &copy; 2025
    <a class="link" href="https://869413421.github.io/">清水泥沙</a>
  </div>
</footer>

  </body>
</html>
